[
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#16910](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/16910.html) (wallet: reduce loading time by using unordered maps by achow101)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.",
      "created_at" : "2019-09-04T07:45:49Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-527784726",
      "id" : 527784726,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUyNzc4NDcyNg==",
      "updated_at" : "2019-11-15T05:44:10Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/527784726",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/39886733?v=4",
         "events_url" : "https://api.github.com/users/DrahtBot/events{/privacy}",
         "followers_url" : "https://api.github.com/users/DrahtBot/followers",
         "following_url" : "https://api.github.com/users/DrahtBot/following{/other_user}",
         "gists_url" : "https://api.github.com/users/DrahtBot/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/DrahtBot",
         "id" : 39886733,
         "login" : "DrahtBot",
         "node_id" : "MDQ6VXNlcjM5ODg2NzMz",
         "organizations_url" : "https://api.github.com/users/DrahtBot/orgs",
         "received_events_url" : "https://api.github.com/users/DrahtBot/received_events",
         "repos_url" : "https://api.github.com/users/DrahtBot/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/DrahtBot/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/DrahtBot/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/DrahtBot"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "re-run ci",
      "created_at" : "2019-09-04T11:26:27Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-527859568",
      "id" : 527859568,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUyNzg1OTU2OA==",
      "updated_at" : "2019-09-04T11:26:27Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/527859568",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/6399679?v=4",
         "events_url" : "https://api.github.com/users/MarcoFalke/events{/privacy}",
         "followers_url" : "https://api.github.com/users/MarcoFalke/followers",
         "following_url" : "https://api.github.com/users/MarcoFalke/following{/other_user}",
         "gists_url" : "https://api.github.com/users/MarcoFalke/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/MarcoFalke",
         "id" : 6399679,
         "login" : "MarcoFalke",
         "node_id" : "MDQ6VXNlcjYzOTk2Nzk=",
         "organizations_url" : "https://api.github.com/users/MarcoFalke/orgs",
         "received_events_url" : "https://api.github.com/users/MarcoFalke/received_events",
         "repos_url" : "https://api.github.com/users/MarcoFalke/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/MarcoFalke/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/MarcoFalke/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/MarcoFalke"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Concept ACK. Thanks for working on this. I did a cursory skim over the code and it looks very readable. The tests are nice too.\r\n\r\nI'll do a more thorough review and some benchmark runs in the next few days. ",
      "created_at" : "2019-09-04T13:52:18Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-527910427",
      "id" : 527910427,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUyNzkxMDQyNw==",
      "updated_at" : "2019-09-04T13:52:18Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/527910427",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/73197?v=4",
         "events_url" : "https://api.github.com/users/jamesob/events{/privacy}",
         "followers_url" : "https://api.github.com/users/jamesob/followers",
         "following_url" : "https://api.github.com/users/jamesob/following{/other_user}",
         "gists_url" : "https://api.github.com/users/jamesob/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/jamesob",
         "id" : 73197,
         "login" : "jamesob",
         "node_id" : "MDQ6VXNlcjczMTk3",
         "organizations_url" : "https://api.github.com/users/jamesob/orgs",
         "received_events_url" : "https://api.github.com/users/jamesob/received_events",
         "repos_url" : "https://api.github.com/users/jamesob/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/jamesob/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/jamesob/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/jamesob"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r321963843"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/321963843"
         }
      },
      "author_association" : "MEMBER",
      "body" : "&lt;language lawyer hat on&gt;\r\n\r\nIs this really defined behaviour? :-)\r\n\r\n&lt;/language lawyer hat on&gt;",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-09-07T10:17:08Z",
      "diff_hunk" : "@@ -0,0 +1,331 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory chunk) at a time. The first call to allocate determine\n+/// the size of elements in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// When the pool is empty, increasingly large blocks of are allocate, doubling its size until\n+/// m_max_num_allocs is reached. This way we don't have too large an overhead for small pool usage,\n+/// and still get efficiency for lots of elements since number of mallocs() are very reduced. Also,\n+/// less bookkeeping is necessary, so it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the T's.\n+///\n+/// Memory layout:\n+///\n+///  m_blocks\n+///        v\n+///    [ nextList, T, T, ... T]\n+///        v\n+///    [ nextList, T, T, ... T]\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Don't allow allocation for types that are smaller than a void*. This does not make sense\n+    /// because we need to fit a pointer into the memory.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(void*), int>::type = 0>\n+    T* Allocate() noexcept\n+    {\n+        return nullptr;\n+    }\n+\n+    /// As with Allocate(), don't allow for types that are smaller than a void*.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(void*), int>::type = 0>\n+    bool Deallocate() noexcept\n+    {\n+        return false;\n+    }\n+\n+    /// Tries to allocate one T. If allocation is not possible, returns nullptr and the callee\n+    /// has to do something else to get memory. First caller decides the size of the pool's data.\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(void*), int>::type = 0>\n+    T* Allocate()\n+    {\n+        if (m_chunk_size == 0) {\n+            // allocator not yet used, so this type determines the size.\n+            m_chunk_size = sizeof(T);\n+        } else if (m_chunk_size != sizeof(T)) {\n+            // allocator's size does not match sizeof(T), don't allocate.\n+            return nullptr;\n+        }\n+\n+        // Make sure we have memory available\n+        if (m_free_chunks == nullptr) {\n+            AllocateAndCreateFreelist();\n+        }\n+\n+        // pop one element from the linked list, returning previous head\n+        auto old_head = m_free_chunks;\n+        m_free_chunks = *reinterpret_cast<void**>(old_head);\n+        return reinterpret_cast<T*>(old_head);\n+    }\n+\n+    /// Puts p back into the freelist, if it was the correct size. Only allowed with objects\n+    /// that were allocated with this pool!\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(void*), int>::type = 0>\n+    bool Deallocate(T* p) noexcept\n+    {\n+        if (m_chunk_size != sizeof(T)) {\n+            // allocation didn't happen with this allocator\n+            return false;\n+        }\n+\n+        // put it into the linked list\n+        *reinterpret_cast<void**>(p) = m_free_chunks;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r321963843",
      "id" : 321963843,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMyMTk2Mzg0Mw==",
      "original_commit_id" : "ad55a26725b015f00f99d99048e992e637aaebf4",
      "original_position" : 111,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : null,
      "pull_request_review_id" : 285166006,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/321963843",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/7826565?v=4",
         "events_url" : "https://api.github.com/users/practicalswift/events{/privacy}",
         "followers_url" : "https://api.github.com/users/practicalswift/followers",
         "following_url" : "https://api.github.com/users/practicalswift/following{/other_user}",
         "gists_url" : "https://api.github.com/users/practicalswift/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/practicalswift",
         "id" : 7826565,
         "login" : "practicalswift",
         "node_id" : "MDQ6VXNlcjc4MjY1NjU=",
         "organizations_url" : "https://api.github.com/users/practicalswift/orgs",
         "received_events_url" : "https://api.github.com/users/practicalswift/received_events",
         "repos_url" : "https://api.github.com/users/practicalswift/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/practicalswift/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/practicalswift"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r321966253"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/321966253"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "hm, I could add a \r\n```cpp\r\nstruct Node {\r\n    Node* next;\r\n};\r\n```\r\nAnd then use `Node*` instead of `void*`. Then instead of \r\n```cpp\r\n// put it into the linked list\r\n*reinterpret_cast<void**>(p) = m_free_chunks;\r\nm_free_chunks = p;\r\n```\r\nI could write \r\n```cpp\r\nauto n = reinterpret_cast<Node*>(p);\r\nn->next = m_free_chunks;\r\nm_free_chunks = n;\r\n```\r\nI guess the code is a bit better readable with that, but I honestly don't know if it's more defined behavior :thinking:",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-09-07T11:54:27Z",
      "diff_hunk" : "@@ -0,0 +1,331 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory chunk) at a time. The first call to allocate determine\n+/// the size of elements in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// When the pool is empty, increasingly large blocks of are allocate, doubling its size until\n+/// m_max_num_allocs is reached. This way we don't have too large an overhead for small pool usage,\n+/// and still get efficiency for lots of elements since number of mallocs() are very reduced. Also,\n+/// less bookkeeping is necessary, so it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the T's.\n+///\n+/// Memory layout:\n+///\n+///  m_blocks\n+///        v\n+///    [ nextList, T, T, ... T]\n+///        v\n+///    [ nextList, T, T, ... T]\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Don't allow allocation for types that are smaller than a void*. This does not make sense\n+    /// because we need to fit a pointer into the memory.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(void*), int>::type = 0>\n+    T* Allocate() noexcept\n+    {\n+        return nullptr;\n+    }\n+\n+    /// As with Allocate(), don't allow for types that are smaller than a void*.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(void*), int>::type = 0>\n+    bool Deallocate() noexcept\n+    {\n+        return false;\n+    }\n+\n+    /// Tries to allocate one T. If allocation is not possible, returns nullptr and the callee\n+    /// has to do something else to get memory. First caller decides the size of the pool's data.\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(void*), int>::type = 0>\n+    T* Allocate()\n+    {\n+        if (m_chunk_size == 0) {\n+            // allocator not yet used, so this type determines the size.\n+            m_chunk_size = sizeof(T);\n+        } else if (m_chunk_size != sizeof(T)) {\n+            // allocator's size does not match sizeof(T), don't allocate.\n+            return nullptr;\n+        }\n+\n+        // Make sure we have memory available\n+        if (m_free_chunks == nullptr) {\n+            AllocateAndCreateFreelist();\n+        }\n+\n+        // pop one element from the linked list, returning previous head\n+        auto old_head = m_free_chunks;\n+        m_free_chunks = *reinterpret_cast<void**>(old_head);\n+        return reinterpret_cast<T*>(old_head);\n+    }\n+\n+    /// Puts p back into the freelist, if it was the correct size. Only allowed with objects\n+    /// that were allocated with this pool!\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(void*), int>::type = 0>\n+    bool Deallocate(T* p) noexcept\n+    {\n+        if (m_chunk_size != sizeof(T)) {\n+            // allocation didn't happen with this allocator\n+            return false;\n+        }\n+\n+        // put it into the linked list\n+        *reinterpret_cast<void**>(p) = m_free_chunks;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r321966253",
      "id" : 321966253,
      "in_reply_to_id" : 321963843,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMyMTk2NjI1Mw==",
      "original_commit_id" : "ad55a26725b015f00f99d99048e992e637aaebf4",
      "original_position" : 111,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : null,
      "pull_request_review_id" : 285168816,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/321966253",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r321999022"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/321999022"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "I got rid of the `void**` casts in in https://github.com/bitcoin/bitcoin/pull/16801/commits/52ee5735304cb8be342e264a19274afc0f422fa8",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-09-08T09:04:09Z",
      "diff_hunk" : "@@ -0,0 +1,331 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory chunk) at a time. The first call to allocate determine\n+/// the size of elements in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// When the pool is empty, increasingly large blocks of are allocate, doubling its size until\n+/// m_max_num_allocs is reached. This way we don't have too large an overhead for small pool usage,\n+/// and still get efficiency for lots of elements since number of mallocs() are very reduced. Also,\n+/// less bookkeeping is necessary, so it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the T's.\n+///\n+/// Memory layout:\n+///\n+///  m_blocks\n+///        v\n+///    [ nextList, T, T, ... T]\n+///        v\n+///    [ nextList, T, T, ... T]\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Don't allow allocation for types that are smaller than a void*. This does not make sense\n+    /// because we need to fit a pointer into the memory.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(void*), int>::type = 0>\n+    T* Allocate() noexcept\n+    {\n+        return nullptr;\n+    }\n+\n+    /// As with Allocate(), don't allow for types that are smaller than a void*.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(void*), int>::type = 0>\n+    bool Deallocate() noexcept\n+    {\n+        return false;\n+    }\n+\n+    /// Tries to allocate one T. If allocation is not possible, returns nullptr and the callee\n+    /// has to do something else to get memory. First caller decides the size of the pool's data.\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(void*), int>::type = 0>\n+    T* Allocate()\n+    {\n+        if (m_chunk_size == 0) {\n+            // allocator not yet used, so this type determines the size.\n+            m_chunk_size = sizeof(T);\n+        } else if (m_chunk_size != sizeof(T)) {\n+            // allocator's size does not match sizeof(T), don't allocate.\n+            return nullptr;\n+        }\n+\n+        // Make sure we have memory available\n+        if (m_free_chunks == nullptr) {\n+            AllocateAndCreateFreelist();\n+        }\n+\n+        // pop one element from the linked list, returning previous head\n+        auto old_head = m_free_chunks;\n+        m_free_chunks = *reinterpret_cast<void**>(old_head);\n+        return reinterpret_cast<T*>(old_head);\n+    }\n+\n+    /// Puts p back into the freelist, if it was the correct size. Only allowed with objects\n+    /// that were allocated with this pool!\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(void*), int>::type = 0>\n+    bool Deallocate(T* p) noexcept\n+    {\n+        if (m_chunk_size != sizeof(T)) {\n+            // allocation didn't happen with this allocator\n+            return false;\n+        }\n+\n+        // put it into the linked list\n+        *reinterpret_cast<void**>(p) = m_free_chunks;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r321999022",
      "id" : 321999022,
      "in_reply_to_id" : 321963843,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMyMTk5OTAyMg==",
      "original_commit_id" : "ad55a26725b015f00f99d99048e992e637aaebf4",
      "original_position" : 111,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : null,
      "pull_request_review_id" : 285204867,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/321999022",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "Here is a graph of another comparison run of the indexing progress over time that I get on my machine (Intel i7-8700 @ 3.20GHz, 32GB of RAM)\r\n\r\n![out](https://user-images.githubusercontent.com/14386/64724584-09da4c00-d4d3-11e9-8888-6586ad5829ba.png)\r\n\r\n* 3432sec for 2019-08-bulkpoolallocator, 4135 sec for master.\r\n* 6.973.488 kbyte max RSS for 2019-08-bulkpoolallocator, 7.643.956 kbyte for master.\r\n\r\nThe straight lines where no progress is made are when the cache is full and then dumped into the leveldb database.\r\n",
      "created_at" : "2019-09-11T18:37:21Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-530510425",
      "id" : 530510425,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzMDUxMDQyNQ==",
      "updated_at" : "2019-09-11T18:39:06Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/530510425",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "author_association" : "NONE",
      "body" : "I want to how to migrate your good bulk pool to my project.",
      "created_at" : "2019-09-12T15:16:45Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-530874101",
      "id" : 530874101,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzMDg3NDEwMQ==",
      "updated_at" : "2019-09-12T15:16:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/530874101",
      "user" : {
         "avatar_url" : "https://avatars1.githubusercontent.com/u/1461362?v=4",
         "events_url" : "https://api.github.com/users/ktprime/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ktprime/followers",
         "following_url" : "https://api.github.com/users/ktprime/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ktprime/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ktprime",
         "id" : 1461362,
         "login" : "ktprime",
         "node_id" : "MDQ6VXNlcjE0NjEzNjI=",
         "organizations_url" : "https://api.github.com/users/ktprime/orgs",
         "received_events_url" : "https://api.github.com/users/ktprime/received_events",
         "repos_url" : "https://api.github.com/users/ktprime/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ktprime/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ktprime/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ktprime"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "> I want to how to migrate your good bulk pool to my project.\r\n\r\nFeel free to copy the bulk_pool.h to your project. It's under the MIT license. I might extract the file into a standalone project with more benchmarks, but thats not high on my priority list.\r\n\r\nI am interested though in any improvements you see with this allocator!",
      "created_at" : "2019-09-12T16:55:26Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-530913306",
      "id" : 530913306,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzMDkxMzMwNg==",
      "updated_at" : "2019-09-12T17:07:24Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/530913306",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Looks like the improvement grows over time/progress? Have you checked with a greater `-stopatheight`?",
      "created_at" : "2019-09-15T23:05:13Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-531607115",
      "id" : 531607115,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzMTYwNzExNQ==",
      "updated_at" : "2019-09-15T23:05:13Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/531607115",
      "user" : {
         "avatar_url" : "https://avatars1.githubusercontent.com/u/3534524?v=4",
         "events_url" : "https://api.github.com/users/promag/events{/privacy}",
         "followers_url" : "https://api.github.com/users/promag/followers",
         "following_url" : "https://api.github.com/users/promag/following{/other_user}",
         "gists_url" : "https://api.github.com/users/promag/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/promag",
         "id" : 3534524,
         "login" : "promag",
         "node_id" : "MDQ6VXNlcjM1MzQ1MjQ=",
         "organizations_url" : "https://api.github.com/users/promag/orgs",
         "received_events_url" : "https://api.github.com/users/promag/received_events",
         "repos_url" : "https://api.github.com/users/promag/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/promag/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/promag/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/promag"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "I've also made a graph with `-stopatheight 594000`: ![out](https://user-images.githubusercontent.com/14386/64935718-fd4b5000-d852-11e9-8c3c-44d0b1171560.png)\r\n",
      "created_at" : "2019-09-16T05:25:30Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-531645046",
      "id" : 531645046,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzMTY0NTA0Ng==",
      "updated_at" : "2019-09-16T05:25:30Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/531645046",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "After running benchmarks across a few different machines, I'm pretty confused.\r\n\r\nThe raw results are below, but the headline is that I'm consistently seeing branches using this allocator outperform master but also *vice versa* depending upon the host. It's about half and half, and when master wins it's by a pretty dramatic margin.\r\n\r\nE.g. master is reliably faster than this branch and #16718 on bench-ssd-2, bench-ssd-5, and bench-hdd-5 (except for one weird run where master took 41 hours??). On all other hosts (ssd-3, ssd-4, hdd-4), these branches beat master consistently.\r\n\r\nThis is very confusing to me because AFAICT -reindex-chainstate should be a deterministic process - i.e. I'd expect the same logical execution for a given height on mainnet regardless of host. I guess maybe blockfile layouts can differ, but would that really be responsible for so dramatic a difference?\r\n\r\nBefore anyone asks: these are dedicated benchmarking machines (specs listed below). Before each run I'm dropping all caches (`sudo /sbin/swapoff -a; sudo /sbin/sysctl vm.drop_caches=3;`), tuning with pyperf (`sudo /usr/local/bin/pyperf system tune;`), and I've ensured that the CPU governors are set to `performance`.\r\n\r\n```\r\nHostname:              bench-ssd-2\r\nKernel:                Linux 4.9.0-8-amd64\r\nOS:                    Debian GNU/Linux 9\r\nRAM (GB):              7.71\r\nArchitecture:          x86_64\r\nCPU(s):                4\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nModel name:            Intel(R) Xeon(R) CPU E3-1220 v5 @ 3.00GHz\r\n```\r\n\r\n```\r\n-reindex-chainstate to 550,000 (dbcache 4000,4000,5000)\r\n\r\n\r\nhostname     branch                               runtime   peak mem  cpu%\r\n--------     ------                               -------   --------  ----\r\n\r\nbench-ssd-2  jamesob/2019-08-robinhood            8:44:15   5268.90MB 356%\r\n                                                  8:44:08   5279.89MB 356%\r\n                                                  8:54:16   6209.94MB 350%\r\n\r\n             master                               3:56:18   6257.37MB 211%\r\n                                                  3:52:25   6322.87MB 215%\r\n                                                  6:09:23   7184.23MB 138%\r\n\r\n             martinus/2019-08-bulkpoolallocator   8:57:44   5680.03MB 349%\r\n                                                  8:57:50   5710.53MB 349%\r\n                                                  9:19:26   6634.91MB 336%\r\n\r\nbench-ssd-3  jamesob/2019-08-robinhood            1:53:11   5288.62MB 88%\r\n                                                  1:56:02   5300.98MB 87%\r\n                                                  2:28:13   6289.06MB 71%\r\n\r\n             martinus/2019-08-bulkpoolallocator   2:14:50   5703.27MB 83%\r\n                                                  2:11:09   5709.48MB 85%\r\n                                                  3:28:15   6747.18MB 56%\r\n\r\n             master                               2:35:11   6272.42MB 88%\r\n                                                  2:32:48   6341.90MB 89%\r\n                                                  5:31:51   7212.80MB 45%\r\n\r\nbench-ssd-4  master                               2:54:59   6268.15MB 79%\r\n                                                  2:35:52   6277.92MB 88%\r\n                                                  5:14:52   7155.87MB 47%\r\n\r\n             jamesob/2019-08-robinhood            1:57:07   5269.11MB 85%\r\n                                                  1:53:59   5351.89MB 88%\r\n                                                  2:28:55   6312.53MB 71%\r\n\r\n             martinus/2019-08-bulkpoolallocator   2:12:36   5715.95MB 84%\r\n                                                  2:09:30   5668.43MB 86%\r\n                                                  3:18:38   6707.09MB 59%\r\n\r\nbench-ssd-5  master                               3:58:37   6263.33MB 210%\r\n                                                  3:40:44   6214.23MB 226%\r\n                                                  5:37:39   7109.82MB 151%\r\n\r\n             martinus/2019-08-bulkpoolallocator   8:53:29   5710.38MB 352%\r\n                                                  8:47:41   5692.83MB 356%\r\n                                                  9:25:06   6553.30MB 333%\r\n\r\n             jamesob/2019-08-robinhood            8:41:53   5294.47MB 357%\r\n                                                  8:36:57   5331.02MB 360%\r\n                                                  8:53:55   6176.95MB 350%\r\n\r\nbench-hdd-4  martinus/2019-08-bulkpoolallocator   3:50:01   5729.15MB 49%\r\n                                                  3:53:44   5793.15MB 47%\r\n                                                  17:20:06  6741.35MB 11%\r\n\r\n             jamesob/2019-08-robinhood            2:55:47   5310.89MB 57%\r\n                                                  2:54:19   5306.11MB 57%\r\n                                                  9:04:22   6220.20MB 19%\r\n\r\n             master                               10:11:25  6257.50MB 23%\r\n                                                  5:25:15   6256.57MB 42%\r\n                                                  40:32:45  7123.75MB 6%\r\n\r\nbench-hdd-5  martinus/2019-08-bulkpoolallocator   10:04:43  5703.16MB 310%\r\n                                                  10:03:57  5775.29MB 311%\r\n                                                  24:04:41  6728.74MB 130%\r\n\r\n             master                               8:05:00   6248.24MB 103%\r\n                                                  6:08:48   6250.89MB 135%\r\n                                                  41:39:38  7152.32MB 20%\r\n\r\n             jamesob/2019-08-robinhood            9:25:51   5295.75MB 329%\r\n                                                  9:24:18   5297.03MB 330%\r\n                                                  13:15:56  6134.24MB 235%\r\n\r\n```\r\n\r\nI'm wondering if this allocator is behaving pathologically based upon some different initial condition across the hosts, but for now I'm pretty stumped. In the coming weeks I'll work on tooling that will allow me to get a more precise idea of where time is being spent and will roll all that into [bitcoinperf](https://github.com/chaincodelabs/bitcoinperf).",
      "created_at" : "2019-09-27T14:44:01Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-535969850",
      "id" : 535969850,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzNTk2OTg1MA==",
      "updated_at" : "2019-09-27T14:44:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/535969850",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/73197?v=4",
         "events_url" : "https://api.github.com/users/jamesob/events{/privacy}",
         "followers_url" : "https://api.github.com/users/jamesob/followers",
         "following_url" : "https://api.github.com/users/jamesob/following{/other_user}",
         "gists_url" : "https://api.github.com/users/jamesob/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/jamesob",
         "id" : 73197,
         "login" : "jamesob",
         "node_id" : "MDQ6VXNlcjczMTk3",
         "organizations_url" : "https://api.github.com/users/jamesob/orgs",
         "received_events_url" : "https://api.github.com/users/jamesob/received_events",
         "repos_url" : "https://api.github.com/users/jamesob/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/jamesob/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/jamesob/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/jamesob"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "It's really strange that the difference is so dramatic. Do you have the debug.log files, or some graphs with the progresss? It would be interesting to see where it's slowing down: e.g. if it's in the DB sync, or continuously, or right *before* a sync.\r\n\r\nI think since your host only has 7.7GB memory the slowdown might come from the host swapping. Maybe the problem is the way bitcoin is handling the cache: As transactions are added to the cache, it slowly gets full.\r\nWith some bad luck / bad configuration, the hashmap's load factor can get full close to the actual dbcache limit. If it has to double it's size right at that time, it will temporarily need a lot more memory than the dbcache, has to rehash, and once this costly operation is done, it will be over the dbcache limit, and the cache is dumped and thrown away. \r\n\r\nSo in that case it would be a much better logic to flush the cache once the load factor reaches maximum, and when another insert would bump it over the limit.",
      "created_at" : "2019-09-28T10:14:03Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-536172801",
      "id" : 536172801,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzNjE3MjgwMQ==",
      "updated_at" : "2019-09-28T10:14:03Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/536172801",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "rebased & squashed in 329754d4c33656b0d526aa456077f4667c6ecb11",
      "created_at" : "2019-10-05T17:08:33Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-538669067",
      "id" : 538669067,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDUzODY2OTA2Nw==",
      "updated_at" : "2019-10-05T17:08:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/538669067",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341266452"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341266452"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Would it be better to drop these methods or to use a static assert, so it could be a compile time error when `sizeof(T) < sizeof(ChunkNode)` instead of a runtime error?",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-10-31T17:18:22Z",
      "diff_hunk" : "@@ -0,0 +1,344 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory block) at a time. The first call to allocate determine\n+/// the size of chunks in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// The size of the allocated blocks are doubled until NUM_CHUNKS_ALLOC_MAX is reached. This way we\n+/// don't have too large an overhead for small pool usage, and still get efficiency for lots of\n+/// elements since number of mallocs() are very reduced. Also, less bookkeeping is necessary, so\n+/// it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the chunks.\n+///\n+/// Memory layout\n+///\n+///  m_blocks\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk3] // block 0\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk7] // block 1\n+///        :\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 12\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 13\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    // Inplace linked list of all allocated blocks. Make sure it is aligned in such a way that whatever comes\n+    // after a BlockNode is correctly aligned.\n+    struct alignas(alignof(::max_align_t)) BlockNode {\n+        // make sure to align\n+        BlockNode* next;\n+    };\n+\n+    // Inplace linked list of the allocation chunks\n+    struct ChunkNode {\n+        ChunkNode* next;\n+    };\n+\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called.\n+    ~Pool() noexcept\n+    {\n+        Destroy();\n+    }\n+\n+    /// Don't allow allocation for types that are smaller than a Node. This does not make sense\n+    /// because we need to fit a pointer into the memory.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341266452",
      "id" : 341266452,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTI2NjQ1Mg==",
      "original_commit_id" : "329754d4c33656b0d526aa456077f4667c6ecb11",
      "original_position" : 84,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : 84,
      "pull_request_review_id" : 310050091,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341266452",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/7133040?v=4",
         "events_url" : "https://api.github.com/users/ryanofsky/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ryanofsky/followers",
         "following_url" : "https://api.github.com/users/ryanofsky/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ryanofsky/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ryanofsky",
         "id" : 7133040,
         "login" : "ryanofsky",
         "node_id" : "MDQ6VXNlcjcxMzMwNDA=",
         "organizations_url" : "https://api.github.com/users/ryanofsky/orgs",
         "received_events_url" : "https://api.github.com/users/ryanofsky/received_events",
         "repos_url" : "https://api.github.com/users/ryanofsky/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ryanofsky/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ryanofsky"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341272476"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341272476"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "More information on this? A quick web search didn't turn up anything for me. Could say more in comment.",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-10-31T17:30:06Z",
      "diff_hunk" : "@@ -0,0 +1,344 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory block) at a time. The first call to allocate determine\n+/// the size of chunks in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// The size of the allocated blocks are doubled until NUM_CHUNKS_ALLOC_MAX is reached. This way we\n+/// don't have too large an overhead for small pool usage, and still get efficiency for lots of\n+/// elements since number of mallocs() are very reduced. Also, less bookkeeping is necessary, so\n+/// it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the chunks.\n+///\n+/// Memory layout\n+///\n+///  m_blocks\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk3] // block 0\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk7] // block 1\n+///        :\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 12\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 13\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    // Inplace linked list of all allocated blocks. Make sure it is aligned in such a way that whatever comes\n+    // after a BlockNode is correctly aligned.\n+    struct alignas(alignof(::max_align_t)) BlockNode {\n+        // make sure to align\n+        BlockNode* next;\n+    };\n+\n+    // Inplace linked list of the allocation chunks\n+    struct ChunkNode {\n+        ChunkNode* next;\n+    };\n+\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called.\n+    ~Pool() noexcept\n+    {\n+        Destroy();\n+    }\n+\n+    /// Don't allow allocation for types that are smaller than a Node. This does not make sense\n+    /// because we need to fit a pointer into the memory.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(ChunkNode), int>::type = 0>\n+    T* Allocate() noexcept\n+    {\n+        return nullptr;\n+    }\n+\n+    /// As with Allocate(), don't allow for types that are smaller than a Node.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(ChunkNode), int>::type = 0>\n+    bool Deallocate() noexcept\n+    {\n+        return false;\n+    }\n+\n+    /// Tries to allocate one T. If allocation is not possible, returns nullptr and the callee\n+    /// has to do something else to get memory. First caller decides the size of the pool's data.\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(ChunkNode), int>::type = 0>\n+    T* Allocate()\n+    {\n+        if (m_chunk_size == 0) {\n+            // allocator not yet used, so this type determines the size.\n+            m_chunk_size = sizeof(T);\n+        } else if (m_chunk_size != sizeof(T)) {\n+            // allocator's size does not match sizeof(T), don't allocate.\n+            return nullptr;\n+        }\n+\n+        // Make sure we have memory available\n+        if (m_free_chunks == nullptr) {\n+            AllocateAndCreateFreelist();\n+        }\n+\n+        // pop one element from the linked list, returning previous head\n+        auto old_head = m_free_chunks;\n+        m_free_chunks = old_head->next;\n+        return reinterpret_cast<T*>(old_head);\n+    }\n+\n+    /// Puts p back into the freelist, if it was the correct size. Only allowed with objects\n+    /// that were allocated with this pool!\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(ChunkNode), int>::type = 0>\n+    bool Deallocate(T* p) noexcept\n+    {\n+        if (m_chunk_size != sizeof(T)) {\n+            // allocation didn't happen with this allocator\n+            return false;\n+        }\n+\n+        // put it into the linked list\n+        auto n = reinterpret_cast<ChunkNode*>(p);\n+        n->next = m_free_chunks;\n+        m_free_chunks = n;\n+        return true;\n+    }\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called. Use with care!\n+    void Destroy() noexcept\n+    {\n+        while (m_blocks != nullptr) {\n+            auto old_head = m_blocks;\n+            m_blocks = m_blocks->next;\n+            ::operator delete(old_head);\n+        }\n+        m_free_chunks = nullptr;\n+    }\n+\n+    /// Counts number of free entries in the freelist. This is an O(n) operation. Mostly for debugging / logging / testing.\n+    size_t NumFreeChunks() const\n+    {\n+        return CountNodes(m_free_chunks);\n+    }\n+\n+    /// Counts number of allocated blocks. This is an O(n) operation. Mostly for debugging / logging / testing.\n+    size_t NumBlocks() const\n+    {\n+        return CountNodes(m_blocks);\n+    }\n+\n+    /// Size per chunk\n+    size_t ChunkSize() const\n+    {\n+        return m_chunk_size;\n+    }\n+\n+private:\n+    //! Minimum number of chunks to allocate for the first block\n+    static constexpr size_t NUM_CHUNKS_ALLOC_MIN = 4;\n+\n+    //! Maximum number of chunks to allocate in one block\n+    static constexpr size_t NUM_CHUNKS_ALLOC_MAX = 16384;\n+\n+    // Counts list length by iterating until nullptr is reached.\n+    template <typename N>\n+    size_t CountNodes(N* node) const\n+    {\n+        size_t length = 0;\n+        while (node != nullptr) {\n+            node = node->next;\n+            ++length;\n+        }\n+        return length;\n+    }\n+\n+    /// Called when no memory is available (m_free_chunks == nullptr).\n+    void AllocateAndCreateFreelist()\n+    {\n+        auto num_chunks = CalcNumChunksToAlloc();\n+        auto data = ::operator new(sizeof(BlockNode) + m_chunk_size * num_chunks);\n+\n+        // link block into blocklist\n+        auto block = reinterpret_cast<BlockNode*>(data);\n+        block->next = m_blocks;\n+        m_blocks = block;\n+\n+        m_free_chunks = MakeFreelist(block, num_chunks);\n+    }\n+\n+    /// Doubles number of elements to alloc until max is reached.\n+    size_t CalcNumChunksToAlloc() noexcept\n+    {\n+        if (m_num_chunks_alloc >= NUM_CHUNKS_ALLOC_MAX) {\n+            return NUM_CHUNKS_ALLOC_MAX;\n+        }\n+        auto prev = m_num_chunks_alloc;\n+        m_num_chunks_alloc *= 2;\n+        return prev;\n+    }\n+\n+    /// Integrates a previously allocated block of memory (where n > 1) into the linked list\n+    ChunkNode* MakeFreelist(BlockNode* block, const size_t num_elements) noexcept\n+    {\n+        // skip BlockNode to get to the chunks\n+        auto const data = reinterpret_cast<char*>(block + 1);\n+\n+        // interlink all chunks\n+        for (size_t i = 0; i < num_elements; ++i) {\n+            reinterpret_cast<ChunkNode*>(data + i * m_chunk_size)->next = reinterpret_cast<ChunkNode*>(data + (i + 1) * m_chunk_size);\n+        }\n+\n+        // last one points nullptr\n+        reinterpret_cast<ChunkNode*>(data + (num_elements - 1) * m_chunk_size)->next = nullptr;\n+        return reinterpret_cast<ChunkNode*>(data);\n+    }\n+\n+    //! A single linked list of all data available in the pool. This list is used for allocations of single elements.\n+    ChunkNode* m_free_chunks{nullptr};\n+\n+    //! A single linked list of all allocated blocks of memory, used to free the data in the destructor.\n+    BlockNode* m_blocks{nullptr};\n+\n+    //! The pool's size for the memory blocks. First call to Allocate() determines the used size.\n+    size_t m_chunk_size{0};\n+\n+    //! Number of elements to allocate in bulk. Doubles each time, until m_max_num_allocs is reached.\n+    size_t m_num_chunks_alloc{NUM_CHUNKS_ALLOC_MIN};\n+};\n+\n+/// Allocator that's usable for node-based containers like std::unorderd_map or std::list. It requires a Pool\n+/// which will be used for allocations of n==1. The pool's memory is only actually freed when the pool's\n+/// destructor is called, otherwise previously allocated memory will be put back into the pool for further use.\n+///\n+/// Be aware that this allocator assumes that the containers will call allocate(1) to allocate nodes, otherwise\n+/// the pool won't be used. Also, it assumes that the *first* call to allocate(1) is done with the actual node\n+/// size. Only subsequent allocate(1) calls with the same sizeof(T) will make use of the allocator.\n+template <typename T>\n+class Allocator\n+{\n+    template <typename U>\n+    friend class Allocator;\n+\n+    template <typename X, typename Y>\n+    friend bool operator==(const Allocator<X>& a, const Allocator<Y>& b) noexcept;\n+\n+public:\n+    using value_type = T;\n+\n+    //! Note: when two containers a and b have different pools and a=b is called, we replace a's allocator with b's.\n+    using propagate_on_container_copy_assignment = std::true_type;\n+    using propagate_on_container_move_assignment = std::true_type;\n+    using propagate_on_container_swap = std::true_type;\n+    using pointer = T*;\n+    using const_pointer = const T*;\n+    using reference = T&;\n+    using const_reference = const T&;\n+    using size_type = size_t;\n+    using difference_type = std::ptrdiff_t;\n+\n+    template <typename U>\n+    struct rebind {\n+        using other = Allocator<U>;\n+    };\n+\n+    explicit Allocator(Pool* pool) noexcept\n+        : m_pool(pool)\n+    {\n+    }\n+\n+    /// Conversion constructor, all Allocators use the same pool.\n+    template <typename U>\n+    Allocator(const Allocator<U>& other) noexcept\n+        : m_pool(other.m_pool)\n+    {\n+    }\n+\n+    /// Allocates n entries. When n==1, the pool is used. The pool might return nullptr if sizeof(T)\n+    /// does not match the pool's chunk size. In that case, we fall back to new().\n+    /// This method should be kept short so it's easily inlineable.\n+    T* allocate(size_t n)\n+    {\n+        if (n == 1) {\n+            auto r = m_pool->Allocate<T>();\n+            if (r != nullptr) {\n+                return r;\n+            }\n+        }\n+        return reinterpret_cast<T*>(::operator new(n * sizeof(T)));\n+    }\n+\n+    /// If n==1, we might have gotten the object from the pool. This is not the case when sizeof(T) does\n+    /// not match the pool's chunk size. In that case, we fall back to delete().\n+    void deallocate(T* p, std::size_t n)\n+    {\n+        if (n == 1 && m_pool->Deallocate(p)) {\n+            return;\n+        }\n+        ::operator delete(p);\n+    }\n+\n+    /// Calls p->~U(). Only required for g++4.8",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341272476",
      "id" : 341272476,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTI3MjQ3Ng==",
      "original_commit_id" : "329754d4c33656b0d526aa456077f4667c6ecb11",
      "original_position" : 312,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : null,
      "pull_request_review_id" : 310050091,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341272476",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/7133040?v=4",
         "events_url" : "https://api.github.com/users/ryanofsky/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ryanofsky/followers",
         "following_url" : "https://api.github.com/users/ryanofsky/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ryanofsky/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ryanofsky",
         "id" : 7133040,
         "login" : "ryanofsky",
         "node_id" : "MDQ6VXNlcjcxMzMwNDA=",
         "organizations_url" : "https://api.github.com/users/ryanofsky/orgs",
         "received_events_url" : "https://api.github.com/users/ryanofsky/received_events",
         "repos_url" : "https://api.github.com/users/ryanofsky/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ryanofsky/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ryanofsky"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341292248"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341292248"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Thanks for having a look at the code! In that case I think it it better to return `nullptr`, because of how it's used in `bulk_pool::Allocator<T>::allocate(size_t n)`. There `bulk_pool::Pool::Allocate()` is called, and if `nullptr` is returned I fall back to `::operator new`\r\n\r\nI could probably rewrite it to be a compile error, but then I need to rewrite `bulk_pool::Allocator<T>::allocate(size_t n)` to handle that case - which I don't know how to do nicely",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-10-31T18:08:54Z",
      "diff_hunk" : "@@ -0,0 +1,344 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory block) at a time. The first call to allocate determine\n+/// the size of chunks in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// The size of the allocated blocks are doubled until NUM_CHUNKS_ALLOC_MAX is reached. This way we\n+/// don't have too large an overhead for small pool usage, and still get efficiency for lots of\n+/// elements since number of mallocs() are very reduced. Also, less bookkeeping is necessary, so\n+/// it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the chunks.\n+///\n+/// Memory layout\n+///\n+///  m_blocks\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk3] // block 0\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk7] // block 1\n+///        :\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 12\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 13\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    // Inplace linked list of all allocated blocks. Make sure it is aligned in such a way that whatever comes\n+    // after a BlockNode is correctly aligned.\n+    struct alignas(alignof(::max_align_t)) BlockNode {\n+        // make sure to align\n+        BlockNode* next;\n+    };\n+\n+    // Inplace linked list of the allocation chunks\n+    struct ChunkNode {\n+        ChunkNode* next;\n+    };\n+\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called.\n+    ~Pool() noexcept\n+    {\n+        Destroy();\n+    }\n+\n+    /// Don't allow allocation for types that are smaller than a Node. This does not make sense\n+    /// because we need to fit a pointer into the memory.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341292248",
      "id" : 341292248,
      "in_reply_to_id" : 341266452,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTI5MjI0OA==",
      "original_commit_id" : "329754d4c33656b0d526aa456077f4667c6ecb11",
      "original_position" : 84,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : 84,
      "pull_request_review_id" : 310083782,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341292248",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341292940"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341292940"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "It seems only g++4.8 requires that this method is present, otherwise I get a compile error. It's deprecated in C++17 and removed in C++20. I'll add a comment for that.",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-10-31T18:10:19Z",
      "diff_hunk" : "@@ -0,0 +1,344 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory block) at a time. The first call to allocate determine\n+/// the size of chunks in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// The size of the allocated blocks are doubled until NUM_CHUNKS_ALLOC_MAX is reached. This way we\n+/// don't have too large an overhead for small pool usage, and still get efficiency for lots of\n+/// elements since number of mallocs() are very reduced. Also, less bookkeeping is necessary, so\n+/// it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the chunks.\n+///\n+/// Memory layout\n+///\n+///  m_blocks\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk3] // block 0\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk7] // block 1\n+///        :\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 12\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 13\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    // Inplace linked list of all allocated blocks. Make sure it is aligned in such a way that whatever comes\n+    // after a BlockNode is correctly aligned.\n+    struct alignas(alignof(::max_align_t)) BlockNode {\n+        // make sure to align\n+        BlockNode* next;\n+    };\n+\n+    // Inplace linked list of the allocation chunks\n+    struct ChunkNode {\n+        ChunkNode* next;\n+    };\n+\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called.\n+    ~Pool() noexcept\n+    {\n+        Destroy();\n+    }\n+\n+    /// Don't allow allocation for types that are smaller than a Node. This does not make sense\n+    /// because we need to fit a pointer into the memory.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(ChunkNode), int>::type = 0>\n+    T* Allocate() noexcept\n+    {\n+        return nullptr;\n+    }\n+\n+    /// As with Allocate(), don't allow for types that are smaller than a Node.\n+    template <typename T, typename std::enable_if<sizeof(T) < sizeof(ChunkNode), int>::type = 0>\n+    bool Deallocate() noexcept\n+    {\n+        return false;\n+    }\n+\n+    /// Tries to allocate one T. If allocation is not possible, returns nullptr and the callee\n+    /// has to do something else to get memory. First caller decides the size of the pool's data.\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(ChunkNode), int>::type = 0>\n+    T* Allocate()\n+    {\n+        if (m_chunk_size == 0) {\n+            // allocator not yet used, so this type determines the size.\n+            m_chunk_size = sizeof(T);\n+        } else if (m_chunk_size != sizeof(T)) {\n+            // allocator's size does not match sizeof(T), don't allocate.\n+            return nullptr;\n+        }\n+\n+        // Make sure we have memory available\n+        if (m_free_chunks == nullptr) {\n+            AllocateAndCreateFreelist();\n+        }\n+\n+        // pop one element from the linked list, returning previous head\n+        auto old_head = m_free_chunks;\n+        m_free_chunks = old_head->next;\n+        return reinterpret_cast<T*>(old_head);\n+    }\n+\n+    /// Puts p back into the freelist, if it was the correct size. Only allowed with objects\n+    /// that were allocated with this pool!\n+    template <typename T, typename std::enable_if<sizeof(T) >= sizeof(ChunkNode), int>::type = 0>\n+    bool Deallocate(T* p) noexcept\n+    {\n+        if (m_chunk_size != sizeof(T)) {\n+            // allocation didn't happen with this allocator\n+            return false;\n+        }\n+\n+        // put it into the linked list\n+        auto n = reinterpret_cast<ChunkNode*>(p);\n+        n->next = m_free_chunks;\n+        m_free_chunks = n;\n+        return true;\n+    }\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called. Use with care!\n+    void Destroy() noexcept\n+    {\n+        while (m_blocks != nullptr) {\n+            auto old_head = m_blocks;\n+            m_blocks = m_blocks->next;\n+            ::operator delete(old_head);\n+        }\n+        m_free_chunks = nullptr;\n+    }\n+\n+    /// Counts number of free entries in the freelist. This is an O(n) operation. Mostly for debugging / logging / testing.\n+    size_t NumFreeChunks() const\n+    {\n+        return CountNodes(m_free_chunks);\n+    }\n+\n+    /// Counts number of allocated blocks. This is an O(n) operation. Mostly for debugging / logging / testing.\n+    size_t NumBlocks() const\n+    {\n+        return CountNodes(m_blocks);\n+    }\n+\n+    /// Size per chunk\n+    size_t ChunkSize() const\n+    {\n+        return m_chunk_size;\n+    }\n+\n+private:\n+    //! Minimum number of chunks to allocate for the first block\n+    static constexpr size_t NUM_CHUNKS_ALLOC_MIN = 4;\n+\n+    //! Maximum number of chunks to allocate in one block\n+    static constexpr size_t NUM_CHUNKS_ALLOC_MAX = 16384;\n+\n+    // Counts list length by iterating until nullptr is reached.\n+    template <typename N>\n+    size_t CountNodes(N* node) const\n+    {\n+        size_t length = 0;\n+        while (node != nullptr) {\n+            node = node->next;\n+            ++length;\n+        }\n+        return length;\n+    }\n+\n+    /// Called when no memory is available (m_free_chunks == nullptr).\n+    void AllocateAndCreateFreelist()\n+    {\n+        auto num_chunks = CalcNumChunksToAlloc();\n+        auto data = ::operator new(sizeof(BlockNode) + m_chunk_size * num_chunks);\n+\n+        // link block into blocklist\n+        auto block = reinterpret_cast<BlockNode*>(data);\n+        block->next = m_blocks;\n+        m_blocks = block;\n+\n+        m_free_chunks = MakeFreelist(block, num_chunks);\n+    }\n+\n+    /// Doubles number of elements to alloc until max is reached.\n+    size_t CalcNumChunksToAlloc() noexcept\n+    {\n+        if (m_num_chunks_alloc >= NUM_CHUNKS_ALLOC_MAX) {\n+            return NUM_CHUNKS_ALLOC_MAX;\n+        }\n+        auto prev = m_num_chunks_alloc;\n+        m_num_chunks_alloc *= 2;\n+        return prev;\n+    }\n+\n+    /// Integrates a previously allocated block of memory (where n > 1) into the linked list\n+    ChunkNode* MakeFreelist(BlockNode* block, const size_t num_elements) noexcept\n+    {\n+        // skip BlockNode to get to the chunks\n+        auto const data = reinterpret_cast<char*>(block + 1);\n+\n+        // interlink all chunks\n+        for (size_t i = 0; i < num_elements; ++i) {\n+            reinterpret_cast<ChunkNode*>(data + i * m_chunk_size)->next = reinterpret_cast<ChunkNode*>(data + (i + 1) * m_chunk_size);\n+        }\n+\n+        // last one points nullptr\n+        reinterpret_cast<ChunkNode*>(data + (num_elements - 1) * m_chunk_size)->next = nullptr;\n+        return reinterpret_cast<ChunkNode*>(data);\n+    }\n+\n+    //! A single linked list of all data available in the pool. This list is used for allocations of single elements.\n+    ChunkNode* m_free_chunks{nullptr};\n+\n+    //! A single linked list of all allocated blocks of memory, used to free the data in the destructor.\n+    BlockNode* m_blocks{nullptr};\n+\n+    //! The pool's size for the memory blocks. First call to Allocate() determines the used size.\n+    size_t m_chunk_size{0};\n+\n+    //! Number of elements to allocate in bulk. Doubles each time, until m_max_num_allocs is reached.\n+    size_t m_num_chunks_alloc{NUM_CHUNKS_ALLOC_MIN};\n+};\n+\n+/// Allocator that's usable for node-based containers like std::unorderd_map or std::list. It requires a Pool\n+/// which will be used for allocations of n==1. The pool's memory is only actually freed when the pool's\n+/// destructor is called, otherwise previously allocated memory will be put back into the pool for further use.\n+///\n+/// Be aware that this allocator assumes that the containers will call allocate(1) to allocate nodes, otherwise\n+/// the pool won't be used. Also, it assumes that the *first* call to allocate(1) is done with the actual node\n+/// size. Only subsequent allocate(1) calls with the same sizeof(T) will make use of the allocator.\n+template <typename T>\n+class Allocator\n+{\n+    template <typename U>\n+    friend class Allocator;\n+\n+    template <typename X, typename Y>\n+    friend bool operator==(const Allocator<X>& a, const Allocator<Y>& b) noexcept;\n+\n+public:\n+    using value_type = T;\n+\n+    //! Note: when two containers a and b have different pools and a=b is called, we replace a's allocator with b's.\n+    using propagate_on_container_copy_assignment = std::true_type;\n+    using propagate_on_container_move_assignment = std::true_type;\n+    using propagate_on_container_swap = std::true_type;\n+    using pointer = T*;\n+    using const_pointer = const T*;\n+    using reference = T&;\n+    using const_reference = const T&;\n+    using size_type = size_t;\n+    using difference_type = std::ptrdiff_t;\n+\n+    template <typename U>\n+    struct rebind {\n+        using other = Allocator<U>;\n+    };\n+\n+    explicit Allocator(Pool* pool) noexcept\n+        : m_pool(pool)\n+    {\n+    }\n+\n+    /// Conversion constructor, all Allocators use the same pool.\n+    template <typename U>\n+    Allocator(const Allocator<U>& other) noexcept\n+        : m_pool(other.m_pool)\n+    {\n+    }\n+\n+    /// Allocates n entries. When n==1, the pool is used. The pool might return nullptr if sizeof(T)\n+    /// does not match the pool's chunk size. In that case, we fall back to new().\n+    /// This method should be kept short so it's easily inlineable.\n+    T* allocate(size_t n)\n+    {\n+        if (n == 1) {\n+            auto r = m_pool->Allocate<T>();\n+            if (r != nullptr) {\n+                return r;\n+            }\n+        }\n+        return reinterpret_cast<T*>(::operator new(n * sizeof(T)));\n+    }\n+\n+    /// If n==1, we might have gotten the object from the pool. This is not the case when sizeof(T) does\n+    /// not match the pool's chunk size. In that case, we fall back to delete().\n+    void deallocate(T* p, std::size_t n)\n+    {\n+        if (n == 1 && m_pool->Deallocate(p)) {\n+            return;\n+        }\n+        ::operator delete(p);\n+    }\n+\n+    /// Calls p->~U(). Only required for g++4.8",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341292940",
      "id" : 341292940,
      "in_reply_to_id" : 341272476,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTI5Mjk0MA==",
      "original_commit_id" : "329754d4c33656b0d526aa456077f4667c6ecb11",
      "original_position" : 312,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : null,
      "pull_request_review_id" : 310084725,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341292940",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341293993"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341293993"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Oh, I see. I didn't realize it would fall back to default operator new. Could mention that explicitly, but this is also fine.",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-10-31T18:12:35Z",
      "diff_hunk" : "@@ -0,0 +1,344 @@\n+// Copyright (c) 2019 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+#define BITCOIN_SUPPORT_ALLOCATORS_BULK_POOL_H\n+\n+#include <cstddef>\n+#include <new>\n+#include <type_traits>\n+#include <utility>\n+\n+namespace bulk_pool {\n+\n+/// This pool allocates one object (memory block) at a time. The first call to allocate determine\n+/// the size of chunks in the pool. Subsequent calls with other types of different size will\n+/// return nullptr. It is designed for use in node-based container like std::unordered_map or\n+/// std::list, where most allocations are for 1 element. It allocates increasingly large blocks\n+/// of memory, and only deallocates at destruction.\n+///\n+/// The size of the allocated blocks are doubled until NUM_CHUNKS_ALLOC_MAX is reached. This way we\n+/// don't have too large an overhead for small pool usage, and still get efficiency for lots of\n+/// elements since number of mallocs() are very reduced. Also, less bookkeeping is necessary, so\n+/// it's more space efficient than allocating one chunk at a time.\n+///\n+/// Deallocate() does not actually free memory, but puts the data into a linked list which can then\n+/// be used for allocate() calls when 1 element is requested. The linked list is in place, reusing\n+/// the memory of the chunks.\n+///\n+/// Memory layout\n+///\n+///  m_blocks\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk3] // block 0\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk7] // block 1\n+///        :\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 12\n+///        v\n+///    [ BlockNode, chunk0, chunk1, ... chunk16383] // block 13\n+///        v\n+///      nullptr\n+///\n+/// m_free_chunks represents a singly linked list of all T's that have been deallocated.\n+class Pool\n+{\n+public:\n+    // Inplace linked list of all allocated blocks. Make sure it is aligned in such a way that whatever comes\n+    // after a BlockNode is correctly aligned.\n+    struct alignas(alignof(::max_align_t)) BlockNode {\n+        // make sure to align\n+        BlockNode* next;\n+    };\n+\n+    // Inplace linked list of the allocation chunks\n+    struct ChunkNode {\n+        ChunkNode* next;\n+    };\n+\n+    /// Explicitly specify the Pool's chunk size. It will only allocate chunks of this size, returning\n+    /// nullptr if a type of different size is specified. If set to 0, the first Allocate() call will\n+    /// determine the chunk size of the pool.\n+    explicit Pool(size_t chunk_size) noexcept\n+        : m_chunk_size(chunk_size)\n+    {\n+    }\n+\n+    /// Doesn't specify the chunk size, so it's determined by the first call to Allocate.\n+    Pool() = default;\n+\n+    // Don't allow moving/copying a pool, it's dangerous\n+    Pool(Pool&&) = delete;\n+    Pool& operator=(Pool&&) = delete;\n+    Pool(const Pool&) = delete;\n+    Pool& operator=(const Pool&) = delete;\n+\n+    /// Deallocates all allocated memory, even when Deallocate() was not yet called.\n+    ~Pool() noexcept\n+    {\n+        Destroy();\n+    }\n+\n+    /// Don't allow allocation for types that are smaller than a Node. This does not make sense\n+    /// because we need to fit a pointer into the memory.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341293993",
      "id" : 341293993,
      "in_reply_to_id" : 341266452,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTI5Mzk5Mw==",
      "original_commit_id" : "329754d4c33656b0d526aa456077f4667c6ecb11",
      "original_position" : 84,
      "path" : "src/support/allocators/bulk_pool.h",
      "position" : 84,
      "pull_request_review_id" : 310086183,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T07:20:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341293993",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/7133040?v=4",
         "events_url" : "https://api.github.com/users/ryanofsky/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ryanofsky/followers",
         "following_url" : "https://api.github.com/users/ryanofsky/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ryanofsky/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ryanofsky",
         "id" : 7133040,
         "login" : "ryanofsky",
         "node_id" : "MDQ6VXNlcjcxMzMwNDA=",
         "organizations_url" : "https://api.github.com/users/ryanofsky/orgs",
         "received_events_url" : "https://api.github.com/users/ryanofsky/received_events",
         "repos_url" : "https://api.github.com/users/ryanofsky/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ryanofsky/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ryanofsky"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341607795"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341607795"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Given that the pool only grows and uses increasing memory over time, and that its lifetime is effectively the lifetime of the entire node, would it make sense to add some kind of garbage collection method for `CCoinsViewCache` that would free unneeded memory (maybe after finishing syncing, or after flushing, or on an interval, or from an RPC a user could call)?",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-11-01T14:54:43Z",
      "diff_hunk" : "@@ -215,10 +216,11 @@ class CCoinsViewCache : public CCoinsViewBacked\n      * declared as \"const\".\n      */\n     mutable uint256 hashBlock;\n-    mutable CCoinsMap cacheCoins;\n+    mutable bulk_pool::Pool cacheCoinsPool{};",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341607795",
      "id" : 341607795,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTYwNzc5NQ==",
      "original_commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "original_position" : 22,
      "path" : "src/coins.h",
      "position" : 22,
      "pull_request_review_id" : 310502054,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T14:54:44Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341607795",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/7133040?v=4",
         "events_url" : "https://api.github.com/users/ryanofsky/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ryanofsky/followers",
         "following_url" : "https://api.github.com/users/ryanofsky/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ryanofsky/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ryanofsky",
         "id" : 7133040,
         "login" : "ryanofsky",
         "node_id" : "MDQ6VXNlcjcxMzMwNDA=",
         "organizations_url" : "https://api.github.com/users/ryanofsky/orgs",
         "received_events_url" : "https://api.github.com/users/ryanofsky/received_events",
         "repos_url" : "https://api.github.com/users/ryanofsky/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ryanofsky/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ryanofsky"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "James walked me through the benchmarks, and I guess a summary is that the benchmarks do generally look good and show expected decreases in runtime and memory usage at varying dbcache sizes.\r\n\r\nThe problem is that in some benchmark setups, reindexing reliably but for no explicable reason takes a lot longer (9 hours vs 2 hours) on the bulk allocator and robinhood branches than it does on the master branch. That is, the robinhood and bulk allocator branches generally perform better in the ways we would expect, but on some particular benchmarking machines with particular datadirs, reindexing takes a *lot* longer when using bulk allocator and robinhood branches instead of the master branch.\r\n\r\nAlso, very strangely, copying the datadir from a benchmarking machine where reindexing with the bulk allocator branch was fast, to a benchmarking machine where reindexing with the bulk allocator branch was slow, somehow makes reindexing on that same machine fast as well. This is suspicious and probably indicates either a mistake made in benchmark setup, or the presence of a pre-existing pathological performance bug in bitcoin somehow triggered by changing the allocator. (But even that doesn't make much sense, because while it's possible to imagine the layout of block data in the datadir impacting reindex time, the actual block reads done during reindexing should be identical between the master and bulk allocator branches.)\r\n\r\nIt does seem like we need to debug the case where switching to the bulk allocator appears to cause reindexing slowdowns with particular datadirs, even though using the bulk allocator could only be causing these slowdowns very indirectly.",
      "created_at" : "2019-11-01T17:32:02Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-548879236",
      "id" : 548879236,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU0ODg3OTIzNg==",
      "updated_at" : "2019-11-01T17:33:44Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/548879236",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/7133040?v=4",
         "events_url" : "https://api.github.com/users/ryanofsky/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ryanofsky/followers",
         "following_url" : "https://api.github.com/users/ryanofsky/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ryanofsky/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ryanofsky",
         "id" : 7133040,
         "login" : "ryanofsky",
         "node_id" : "MDQ6VXNlcjcxMzMwNDA=",
         "organizations_url" : "https://api.github.com/users/ryanofsky/orgs",
         "received_events_url" : "https://api.github.com/users/ryanofsky/received_events",
         "repos_url" : "https://api.github.com/users/ryanofsky/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ryanofsky/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ryanofsky"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Just as an update, I've got a plan for diagnosing the benching weirdness I've seen thus far. With any luck I'll be posting an analysis (or at least additional information) in the next few days.",
      "created_at" : "2019-11-01T18:17:30Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-548896153",
      "id" : 548896153,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU0ODg5NjE1Mw==",
      "updated_at" : "2019-11-01T18:17:30Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/548896153",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/73197?v=4",
         "events_url" : "https://api.github.com/users/jamesob/events{/privacy}",
         "followers_url" : "https://api.github.com/users/jamesob/followers",
         "following_url" : "https://api.github.com/users/jamesob/following{/other_user}",
         "gists_url" : "https://api.github.com/users/jamesob/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/jamesob",
         "id" : 73197,
         "login" : "jamesob",
         "node_id" : "MDQ6VXNlcjczMTk3",
         "organizations_url" : "https://api.github.com/users/jamesob/orgs",
         "received_events_url" : "https://api.github.com/users/jamesob/received_events",
         "repos_url" : "https://api.github.com/users/jamesob/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/jamesob/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/jamesob/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/jamesob"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "Is it possible that this weirdness can be explained by different assumedvalid points? Either in the branches, or on the disk. It was a surprise to me: https://github.com/bitcoin/bitcoin/pull/17060#issuecomment-547674256\r\n\r\nAs @MarcoFalke wrote in https://github.com/bitcoin/bitcoin/pull/17060#issuecomment-547687821, it is probably best to either use `-noassumevalid` or use the same block hash, and make sure that block is actually available on all disks\r\n\r\n",
      "created_at" : "2019-11-01T18:25:58Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-548899136",
      "id" : 548899136,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU0ODg5OTEzNg==",
      "updated_at" : "2019-11-01T18:25:58Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/548899136",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341716163"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341716163"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "I have the following code for something i'm working on. It should be amortized cheap to call after every erase; you could also make it have different parameters during sync or after (e.g, always compact after sync, only compact if it's above 50MB free during sync).\r\n```c++\r\n static void resize_if_savings(CTxMemPoolEntry::relatives& relatives) {\r\n       assert(relatives.max_load_factor() == 1)\r\n       // If we're at 0, clear out the map\r\n       if (relatives.size() == 0) {\r\n           CTxMemPool::relatives tmp;\r\n           std::swap(tmp, relatives);\r\n           return;\r\n       }\r\n       // don't bother saving for small enough sets\r\n       // 19 buckets isn't very large, and fits in with the usual\r\n       // prime rehash policies\r\n       if (relatives.bucket_count() <= 19) return;\r\n       // don't bother rehashing if we're more than half full\r\n       const size_t full_size = relatives.bucket_count();\r\n       if (relatives.size() > full_size/2) return;\r\n   \r\n       CTxMemPool::relatives tmp{std::make_move_iterator(relatives.begin()), std::make_move_iterator(relatives.end()), relatives.size()};\r\n       std::swap(tmp, relatives);\r\n   }\r\n```",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-11-01T19:16:23Z",
      "diff_hunk" : "@@ -215,10 +216,11 @@ class CCoinsViewCache : public CCoinsViewBacked\n      * declared as \"const\".\n      */\n     mutable uint256 hashBlock;\n-    mutable CCoinsMap cacheCoins;\n+    mutable bulk_pool::Pool cacheCoinsPool{};",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341716163",
      "id" : 341716163,
      "in_reply_to_id" : 341607795,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTcxNjE2Mw==",
      "original_commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "original_position" : 22,
      "path" : "src/coins.h",
      "position" : 22,
      "pull_request_review_id" : 310647224,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-01T19:16:24Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341716163",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/886523?v=4",
         "events_url" : "https://api.github.com/users/JeremyRubin/events{/privacy}",
         "followers_url" : "https://api.github.com/users/JeremyRubin/followers",
         "following_url" : "https://api.github.com/users/JeremyRubin/following{/other_user}",
         "gists_url" : "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/JeremyRubin",
         "id" : 886523,
         "login" : "JeremyRubin",
         "node_id" : "MDQ6VXNlcjg4NjUyMw==",
         "organizations_url" : "https://api.github.com/users/JeremyRubin/orgs",
         "received_events_url" : "https://api.github.com/users/JeremyRubin/received_events",
         "repos_url" : "https://api.github.com/users/JeremyRubin/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/JeremyRubin/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/JeremyRubin"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341808938"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341808938"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "@JeremyRubin that looks interesting. I think the `if (relatives.size() > full_size/2) return;` is a bit too aggressive though. For a hashmap uses doubling as resize strategy: if it has e.g. 256 elements and you add one it will double its size, and when you remove one element again it would already trigger the rehashing to decrease its size.",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-11-02T12:06:34Z",
      "diff_hunk" : "@@ -215,10 +216,11 @@ class CCoinsViewCache : public CCoinsViewBacked\n      * declared as \"const\".\n      */\n     mutable uint256 hashBlock;\n-    mutable CCoinsMap cacheCoins;\n+    mutable bulk_pool::Pool cacheCoinsPool{};",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341808938",
      "id" : 341808938,
      "in_reply_to_id" : 341607795,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTgwODkzOA==",
      "original_commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "original_position" : 22,
      "path" : "src/coins.h",
      "position" : 22,
      "pull_request_review_id" : 310767991,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-02T12:06:35Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341808938",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341826698"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341826698"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "On my system the rehash policy is the  prime less than double policy, which ensures that we have a growth factor < 2 for all resizes. So in the case of 256, we would first \"double\" to 503. Then we would be at 257/503 \"fullness\", where half would be 251. So we can remove up to 6 elements before triggering a re-hash. So the pathological cases are a bit more precise, see below:\r\n\r\n\r\nIf you're at exactly 251, then you add one, you double to 503, and then you can remove two before triggering a rehash (strict inequality). Let's say you choose to remove a third. Then you'll rehash to either 467 or 257 (implementations depending -- I believe it's usually 257 because we go to the smallest prime larger than N). That means you will need to remove down to 233 (~20 more elements) before triggering a rehash OR more likely ~125 elements. Let's say instead, if you add back another N, you won't trigger a rehash until you hit 467, so you can add back another ~215 elements before having to go again OR more likely, 7 elements.\r\n\r\nSo there is a case to be made that it's less than ideal, but it's not quite as bad given the primes.\r\n\r\nThere's also a case to be made (at least for the use cases I'm looking at) where you're usually in a streak of erases, followed by a streak of adds. So while it is possible to trigger the bad behavior, it's atypical.\r\n\r\nTherefore I don't actually think it's that bad to use half as the shrink test, given that it quickly gets us shrunk to a more than half full table.\r\n\r\nBut if we do a resize at, say, at n <= (buckets - (buckets/100)*54), and resize to (n + (n/100)*36), then we can always be able to add at least 36% after a resize and remove 1/(1 + 0.36*1.08) - 0.36 ~~ 36% more before resizing again.  (The ~1.08 more than 36% I think, is half the average overshoot prime to prime. This is not a great estimate but can be improved).",
      "commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "created_at" : "2019-11-02T21:34:04Z",
      "diff_hunk" : "@@ -215,10 +216,11 @@ class CCoinsViewCache : public CCoinsViewBacked\n      * declared as \"const\".\n      */\n     mutable uint256 hashBlock;\n-    mutable CCoinsMap cacheCoins;\n+    mutable bulk_pool::Pool cacheCoinsPool{};",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#discussion_r341826698",
      "id" : 341826698,
      "in_reply_to_id" : 341607795,
      "node_id" : "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTgyNjY5OA==",
      "original_commit_id" : "54ada87348dbaa963490547b342ce57b4249987e",
      "original_position" : 22,
      "path" : "src/coins.h",
      "position" : 22,
      "pull_request_review_id" : 310789614,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/16801",
      "updated_at" : "2019-11-02T21:34:04Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341826698",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/886523?v=4",
         "events_url" : "https://api.github.com/users/JeremyRubin/events{/privacy}",
         "followers_url" : "https://api.github.com/users/JeremyRubin/followers",
         "following_url" : "https://api.github.com/users/JeremyRubin/following{/other_user}",
         "gists_url" : "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/JeremyRubin",
         "id" : 886523,
         "login" : "JeremyRubin",
         "node_id" : "MDQ6VXNlcjg4NjUyMw==",
         "organizations_url" : "https://api.github.com/users/JeremyRubin/orgs",
         "received_events_url" : "https://api.github.com/users/JeremyRubin/received_events",
         "repos_url" : "https://api.github.com/users/JeremyRubin/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/JeremyRubin/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/JeremyRubin"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Okay, I'm back with good news and bad(ish) news. The good news is that the bench weirdness has been resolved by comparing master (6a7c40bee4, [`bench/master.1`](https://github.com/jamesob/bitcoin/tree/bench/master.1)) to a version of this branch rebased on top of that same commit ([`bench/alloc.1`](https://github.com/jamesob/bitcoin/tree/bench/alloc.1)). So I'm guessing the weirdness before may have been related to an assumevalid bump, but I'm not definitively sure.\r\n\r\nThe bad news is that the now-very-consistent results don't show as much of an improvement as I expected. \r\n\r\nI did two separate runs over the course of a few days - for each machine, the branches were tested twice back-to-back in random order (results are ordered the same). The command tested was `bitcoind -reindex-chainstate -stopatheight=550000 -dbcache=$DBCACHE -connect=0`.\r\n\r\n```\r\nhost         branch                 time              %     maxmem  cpu% dbcache\r\nbench-ssd-2  bench/master.1             9:13:57    1.00  5777.93MB 344% dbcache=4000MB\r\nbench-ssd-2  bench/master.1             9:16:30    1.00  5760.55MB 343% dbcache=4000MB\r\nbench-ssd-2  bench/alloc.1              9:01:19    0.97  5466.12MB 348% dbcache=4000MB\r\nbench-ssd-2  bench/alloc.1              9:01:06    0.97  5453.22MB 349% dbcache=4000MB\r\n\r\nbench-ssd-3  bench/alloc.1              9:03:00    0.97  5451.97MB 348% dbcache=4000MB\r\nbench-ssd-3  bench/alloc.1              9:01:58    0.97  5474.70MB 348% dbcache=4000MB\r\nbench-ssd-3  bench/master.1             9:16:33    1.00  5772.59MB 343% dbcache=4000MB\r\nbench-ssd-3  bench/master.1             9:18:04    1.00  5781.47MB 342% dbcache=4000MB\r\n\r\nbench-ssd-4  bench/master.1             9:15:28    1.00  5781.36MB 343% dbcache=4000MB\r\nbench-ssd-4  bench/master.1             9:15:41    1.00  5765.45MB 343% dbcache=4000MB\r\nbench-ssd-4  bench/alloc.1              9:02:24    0.98  5451.96MB 348% dbcache=4000MB\r\nbench-ssd-4  bench/alloc.1              9:01:49    0.98  5443.95MB 348% dbcache=4000MB\r\n\r\nbench-ssd-5  bench/alloc.1              8:57:42    0.97  5456.22MB 351% dbcache=4000MB\r\nbench-ssd-5  bench/alloc.1              8:57:48    0.97  5464.43MB 351% dbcache=4000MB\r\nbench-ssd-5  bench/master.1             9:12:06    1.00  5787.68MB 345% dbcache=4000MB\r\nbench-ssd-5  bench/master.1             9:11:49    1.00  5777.87MB 346% dbcache=4000MB\r\n\r\nbench-strong bench/alloc.1              14:58:34   0.99  5425.66MB 548% dbcache=4000MB\r\nbench-strong bench/alloc.1              14:57:55   0.99  5463.18MB 548% dbcache=4000MB\r\nbench-strong bench/master.1             15:04:45   1.00  5751.64MB 545% dbcache=4000MB\r\nbench-strong bench/master.1             15:04:06   1.00  5734.97MB 545% dbcache=4000MB\r\n```\r\n\r\nSo we see very consistent times across branches and machines, but the gain associated with this branch is pretty mild (~2-3%).\r\n\r\nAll of the bench-ssd-* machines resemble each other pretty closely. `bench-strong` has much more CPU and RAM (which led me to be initially surprised by the results) but then I realized it has a spinning disk. The specs for the machines are below:\r\n\r\n#### (representative of the bench-ssd-* machines)\r\n| key                                  | value                                       |\r\n| ----------------------------------   | -----------------------------------------   |\r\n| hostname                             | bench-ssd-2                                 |\r\n| cpu_model_name                       | Intel(R) Xeon(R) CPU E3-1220 v5 @ 3.00GHz   |\r\n| ram_gb                               | 7.712375640869141                           |\r\n| os                                   | ['Debian GNU/Linux', '9', 'stretch']        |\r\n| arch                                 | x86_64                                      |\r\n| kernel                               | 4.9.0-8-amd64                               |\r\n| read_iops (/home/ccl/bitcoinperf)    | 2032                                        |\r\n| write_iops (/home/ccl/bitcoinperf)   | 672                                         |\r\n\r\n#### bench-strong\r\n| key                                 | value                                     |\r\n| ---------------------------------   | ---------------------------------------   |\r\n| hostname                            | bench-strong                              |\r\n| cpu_model_name                      | Intel(R) Core(TM) i7-4770 CPU @ 3.40GHz   |\r\n| ram_gb                              | 31.353431701660156                        |\r\n| os                                  | ['Debian GNU/Linux', '10', 'buster']      |\r\n| arch                                | x86_64                                    |\r\n| kernel                              | 4.19.0-5-amd64                            |\r\n| read_iops (/home/james/.bitcoin)    | 332                                       |\r\n| write_iops (/home/james/.bitcoin)   | 113                                       |\r\n\r\nIn order to make certain that these runtime characteristics aren't unstable based on dbcache, I reran this with `dbcache=5000` (from `dbcache=4000`) - in previous benchmarking sessions I hadn't seen the weird \"bi-modal\" behavior until dbcache hit 5000.\r\n\r\n```\r\nhost         branch                 time              %     maxmem  cpu% dbcache\r\nbench-ssd-2  bench/alloc.1              9:12:44    0.98  6397.99MB 341% dbcache=5000MB\r\nbench-ssd-2  bench/alloc.1              9:11:06    0.98  6397.02MB 342% dbcache=5000MB\r\nbench-ssd-2  bench/master.1             9:22:27    1.00  6697.26MB 340% dbcache=5000MB\r\nbench-ssd-2  bench/master.1             9:22:28    1.00  6609.71MB 339% dbcache=5000MB\r\n\r\nbench-ssd-3  bench/master.1             9:27:27    1.00  6738.98MB 336% dbcache=5000MB\r\nbench-ssd-3  bench/master.1             9:24:56    1.00  6770.75MB 338% dbcache=5000MB\r\nbench-ssd-3  bench/alloc.1              9:25:38    1.00  6454.57MB 334% dbcache=5000MB\r\nbench-ssd-3  bench/alloc.1              9:12:47    0.97  6418.94MB 341% dbcache=5000MB\r\n\r\nbench-ssd-4  bench/alloc.1              9:12:12    0.98  6543.72MB 341% dbcache=5000MB\r\nbench-ssd-4  bench/alloc.1              9:26:04    1.00  6394.11MB 333% dbcache=5000MB\r\nbench-ssd-4  bench/master.1             9:23:44    1.00  6749.35MB 338% dbcache=5000MB\r\nbench-ssd-4  bench/master.1             9:22:57    0.99  6673.99MB 339% dbcache=5000MB\r\n\r\nbench-ssd-5  bench/alloc.1              9:04:42    0.97  6380.43MB 346% dbcache=5000MB\r\nbench-ssd-5  bench/alloc.1              9:06:23    0.97  6380.80MB 345% dbcache=5000MB\r\nbench-ssd-5  bench/master.1             9:23:53    1.00  6666.49MB 338% dbcache=5000MB\r\nbench-ssd-5  bench/master.1             9:20:08    0.99  6604.82MB 341% dbcache=5000MB\r\n\r\nbench-strong bench/master.1             15:00:44   1.00  6869.63MB 545% dbcache=5000MB\r\nbench-strong bench/master.1             14:58:43   1.00  6706.32MB 546% dbcache=5000MB\r\nbench-strong bench/alloc.1              15:02:07   1.00  6511.17MB 545% dbcache=5000MB\r\nbench-strong bench/alloc.1              15:02:24   1.00  6415.48MB 545% dbcache=5000MB\r\n```\r\n\r\nAs you can see, the results are very similar. In fact I was a little surprised that an extra gig of dbcache doesn't seem to make any real difference in terms of runtime - if nothing else it marginally hurt the runtimes.\r\n\r\n---\r\n\r\nSo anyway, take this all for what it is. I wouldn't be surprised if after the wide variance seen in my benchmarking that this is all taken with a grain of salt, but I've done what I can to rule out spurious measures. That said, anyone should be able to reproduce these results by making superficial modifications to [this script](https://github.com/chaincodelabs/bitcoinperf/blob/master/bin/run_remote_reindex.py).\r\n\r\nI would say if these benchmarks are indeed characteristic of the performance gain associated with this PR, I am not in favor of merging it as such because I think the risk associated with swapping out an allocator isn't compensated for by a 3% reduction in IBD runtime. But that said I am (hopefully obviously) a big fan of this sort of work, and will continue to cheer @martinus on in his attempts to optimize what is certainly one of the biggest bottlenecks in bitcoind.",
      "created_at" : "2019-11-08T15:58:01Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-551883348",
      "id" : 551883348,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU1MTg4MzM0OA==",
      "updated_at" : "2019-11-08T15:58:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/551883348",
      "user" : {
         "avatar_url" : "https://avatars0.githubusercontent.com/u/73197?v=4",
         "events_url" : "https://api.github.com/users/jamesob/events{/privacy}",
         "followers_url" : "https://api.github.com/users/jamesob/followers",
         "following_url" : "https://api.github.com/users/jamesob/following{/other_user}",
         "gists_url" : "https://api.github.com/users/jamesob/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/jamesob",
         "id" : 73197,
         "login" : "jamesob",
         "node_id" : "MDQ6VXNlcjczMTk3",
         "organizations_url" : "https://api.github.com/users/jamesob/orgs",
         "received_events_url" : "https://api.github.com/users/jamesob/received_events",
         "repos_url" : "https://api.github.com/users/jamesob/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/jamesob/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/jamesob/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/jamesob"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "Thanks for getting to the bottom of this @jamesob! It's good to see that the allocator actually seems to do it's job as it's supposed to be, even when the benefit is small. It's probably bigger when validation doesn't have be be redone, but the additional code complexity is probably not worth it. ",
      "created_at" : "2019-11-08T16:29:51Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-551896168",
      "id" : 551896168,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU1MTg5NjE2OA==",
      "updated_at" : "2019-11-08T16:29:51Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/551896168",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "> It's probably bigger when validation doesn't have be be redone, but the additional code complexity is probably not worth it.\r\n\r\nIt seems like a pool allocator could be a basic building block for a lot of future optimizations. It might also be useful for testing overhead of allocations even in places where we wouldn't want to enable it in released code. So I could see the effort here being useful even if we aren't looking to merge the PR now. But would suggest closing the PR or marking it work in progress to update the status.\r\n\r\nOne thing I'm not clear on is the difference between 3% performance improvement last measured and 16% initially measured. If there are theories about this, I'd be curious.",
      "created_at" : "2019-11-18T20:44:29Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-555200787",
      "id" : 555200787,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU1NTIwMDc4Nw==",
      "updated_at" : "2019-11-18T20:44:29Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/555200787",
      "user" : {
         "avatar_url" : "https://avatars2.githubusercontent.com/u/7133040?v=4",
         "events_url" : "https://api.github.com/users/ryanofsky/events{/privacy}",
         "followers_url" : "https://api.github.com/users/ryanofsky/followers",
         "following_url" : "https://api.github.com/users/ryanofsky/following{/other_user}",
         "gists_url" : "https://api.github.com/users/ryanofsky/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/ryanofsky",
         "id" : 7133040,
         "login" : "ryanofsky",
         "node_id" : "MDQ6VXNlcjcxMzMwNDA=",
         "organizations_url" : "https://api.github.com/users/ryanofsky/orgs",
         "received_events_url" : "https://api.github.com/users/ryanofsky/received_events",
         "repos_url" : "https://api.github.com/users/ryanofsky/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/ryanofsky/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/ryanofsky"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "> One thing I'm not clear on is the difference between 3% performance improvement last measured and 16% initially measured. If there are theories about this, I'd be curious.\r\n\r\nI'm pretty sure the difference is due to to additional validation due to `-noassumevalid`. With validation, validation is the bottleneck so the improvement is not as pronounced. When no validation needs to happen, you see much bigger gains from this PR.",
      "created_at" : "2019-11-19T07:24:34Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/16801#issuecomment-555370503",
      "id" : 555370503,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/16801",
      "node_id" : "MDEyOklzc3VlQ29tbWVudDU1NTM3MDUwMw==",
      "updated_at" : "2019-11-19T07:24:34Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/555370503",
      "user" : {
         "avatar_url" : "https://avatars3.githubusercontent.com/u/14386?v=4",
         "events_url" : "https://api.github.com/users/martinus/events{/privacy}",
         "followers_url" : "https://api.github.com/users/martinus/followers",
         "following_url" : "https://api.github.com/users/martinus/following{/other_user}",
         "gists_url" : "https://api.github.com/users/martinus/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/martinus",
         "id" : 14386,
         "login" : "martinus",
         "node_id" : "MDQ6VXNlcjE0Mzg2",
         "organizations_url" : "https://api.github.com/users/martinus/orgs",
         "received_events_url" : "https://api.github.com/users/martinus/received_events",
         "repos_url" : "https://api.github.com/users/martinus/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/martinus/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/martinus/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/martinus"
      }
   }
]
